# -*- coding: utf-8 -*-
import json
import requests
import time
import datetime



#Initial load of DTG_Bot information. The JSON file contains a lot of information including the posts that we want.
ResetBotURLCurl="https://www.reddit.com/user/DTG_Bot/.json"
response = requests.get(ResetBotURLCurl)

#Time formatting for the thread title
today = str(datetime.date.today())
#today="2018-09-28"
string_post="[D2] Weekly Reset Thread ["+today+"]"

#There are a few delay commands here. These are for the Reddit anti-bot scripts which block requests that are too timed together. 
time.sleep(3)
parse=response.json()
# This delay tries to help parsing the data
time.sleep(3)
# If the amount of text is small - we know that our request got denied by the anti-bot scripts. The next step evaluates the size of the returned text
test_reddit= len(json.dumps(parse))

#1000 characters is arbitrary but the normal response is about 36000. So this works pretty well
if test_reddit <1000:
   reprocess=1
   print("Bad DTG_Bot Load")
   time.sleep(5)
   #So we are just going to repeat the previous process 40 times until we get a good response. It's ugly but it works and we shouldn't need oauth to only read a public page.
   for x in range(0,40):
      if reprocess==1:
         response = requests.get(ResetBotURLCurl)
         time.sleep(3)
         parse=response.json()
         time.sleep(3)
         test_reddit= len(json.dumps(parse))
         if test_reddit >1000:
            print("Reddit attempt " +str(x) +" worked!")
            reprocess=0
         else:
            print("Reddit attempt " +str(x) +" did not work")
            time.sleep(7)
            
#At this point we should have a good response
#Now we will look at the last 20 posts from DTG_Bot to figure out which one is the megathread
#The second line is to prevent an error in reading a json dictionary element that won't exist in a comment. "kind" "t3" = post, "kind" "t1" = comment in the thread. 
for y in range(0,20):
   if parse["data"]["children"][y]["kind"]=="t3":
      test=parse["data"]["children"][y]["data"]["title"]
      #If this post is the megathread we want - grab the text. Otherwise move to the next post. 
      if test==string_post:
         resettext=parse["data"]["children"][y]["data"]["selftext"]

#Now that we have all the text we need to do two things
# (1) Break apart the text (around 6500 characters) into two parts because slack limits a message to 4000 characters
# (2) Sanitize the reset post because it contains a Shaxx quote. <--- took me 2 hours to figure that out
length=len(resettext)
resettext2=resettext[1:3000]
resettextpartone=resettext2.replace('"','')
resettextparttwo=resettext[3001,length]

#send the text to Slack
headers = {'Content-type': 'application/json'}
payload = '{"text":" <!channel> Here are the changes for this weekly reset: \n \n' + resettextpartone + ' " }'
payload2 ='{"text":" ' + resettextparttwo + ' " }'

r = requests.post('YOUR WEBHOOK HERE', data=payload.encode('utf8'), headers=headers)
r2 = requests.post('YOUR WEBHOOK HERE', data=payload2.encode('utf8'), headers=headers)


